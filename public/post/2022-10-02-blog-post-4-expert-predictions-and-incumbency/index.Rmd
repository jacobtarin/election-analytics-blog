---
title: 'Blog Post 4: Expert Predictions and Incumbency'
author: Jacob Moore
date: '2022-10-02'
slug: []
categories: []
tags: []
---

```{r setup, include=FALSE}
library(tidyverse)
library(sf)
library(plotly)

# Reading in data (Thank you to Ethan Jasny for the expert ratings datset)
dist_polls <- read_csv("../data/dist_polls_2018-2022.csv")
incumbents <- read_csv("../data/incumb_dist_1948-2020.csv")
expert_ratings <- read_csv("../data/2018_ratings_share.csv")
historical_results <- read_csv("../data/house party vote share by district 1948-2020.csv")
cd114 <- st_read("../data/districtShapes/districts114.shp", quiet = TRUE)

# Clean election data
election_2018 <- historical_results %>% 
  filter(raceYear == 2018) %>% 
  select(State, raceYear, Area, RepVotesMajorPercent, DemVotesMajorPercent,
         CD, state_abb, district_num, district_id, WinnerParty) %>% 
  mutate(CD = case_when(district_num == 0 ~ paste(state_abb, "01", sep = "-"),
                        district_num != 0 ~ CD))

# Add margin predictions to expert ratings
expert_ratings <- expert_ratings %>% 
  mutate(cpr_margin = case_when(
    cpr == "Solid Democratic" ~ 60,
    cpr == "Likely Democratic" ~ 55,
    cpr == "Lean Democratic" ~ 52.5,
    cpr == "Toss-up" ~ 50,
    cpr == "Lean Republican" ~ 47.5,
    cpr == "Likely Republican" ~ 45,
    cpr == "Solid Republican" ~ 40
  )) %>% 
  mutate(crystal_ball_margin = case_when(
    crystal_ball == "Safe Democratic" ~ 60,
    crystal_ball == "Likely Democratic" ~ 55,
    crystal_ball == "Lean Democratic" ~ 52.5,
    crystal_ball == "Toss-up" ~ 50,
    crystal_ball == "Lean Republican" ~ 47.5,
    crystal_ball == "Likely Republican" ~ 45,
    crystal_ball == "Safe Republican" ~ 40
  )) %>% 
  mutate(inside_elections_margin = case_when(
    inside_elections == "Solid Democratic" ~ 60,
    inside_elections == "Likely Democratic" ~ 55,
    inside_elections == "Lean Democratic" ~ 52.5,
    inside_elections == "Tilt Democratic" ~ 51.5,
    inside_elections == "Toss-up" ~ 50,
    inside_elections == "Tilt Republican" ~ 48.5,
    inside_elections == "Lean Republican" ~ 47.5,
    inside_elections == "Likely Republican" ~ 45,
    inside_elections == "Solid Republican" ~ 40
  )) %>% 
  mutate(avg_margin = (cpr_margin + crystal_ball_margin + inside_elections_margin)/3)

# Join election data and expert ratings
election_2018 <- election_2018 %>% 
  inner_join(expert_ratings, by = c("CD" = "District")) %>% 
  rename(STATENAME = State, DISTRICT = district_num) %>% 
  mutate(DISTRICT = as.character(DISTRICT),
         expert_diff = avg_margin - DemVotesMajorPercent)

# Clean and simplify shapefiles for join
cd114 <- st_make_valid(cd114)
cd114 <- st_simplify(cd114, preserveTopology = TRUE, dTolerance = 1000)
cd114 <- cd114 %>% left_join(election_2018, by = c("DISTRICT", "STATENAME"))

vote_share_actual <- ggplot() + 
  geom_sf(data = cd114, aes(fill = DemVotesMajorPercent),
          inherit.aes = FALSE, alpha = 0.9) + 
  scale_fill_gradient2(low = "red", mid = "#ececec", high = "blue",
                       midpoint = 50, limits = c(0, 100)) +
  coord_sf(xlim = c(-126.43, -66.57), ylim = c(23, 51), expand = FALSE) + 
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "2018 Democratic Party Vote Share by District",
       fill = "D-Vote %")

vote_share_predicted <- ggplot() + 
  geom_sf(data = cd114, aes(fill = avg_margin),
          inherit.aes = FALSE, alpha = 0.9) + 
  scale_fill_gradient2(low = "red", mid = "#ececec", high = "blue",
                       midpoint = 50, limits = c(0, 100)) +
  coord_sf(xlim = c(-126.43, -66.57), ylim = c(23, 51), expand = FALSE) + 
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "2018 Expert Predictions",
       fill = "D-Vote %")

vote_share_difference <- ggplot() + 
  geom_sf(data = cd114, aes(fill = expert_diff),
          inherit.aes = FALSE, alpha = 0.9) + 
  scale_fill_gradient2(low = "red", mid = "#ececec", high = "blue",
                       midpoint = 0, limits = c(-40, 40)) +
  coord_sf(xlim = c(-126.43, -66.57), ylim = c(23, 51), expand = FALSE) + 
  theme_void() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(title = "Expert Prediction Differences",
       fill = "Predicted Minus Actual")
```

This week I'll be looking at expert predictions and incumbency to help build my model for the upcoming 2022 midterm election. I'll start by assessing the accuracy of expert predictions in the 2018 midterm elections before incorporating incumbency and potentially expert predictions into my model.

# Expert Predictions

I am not alone when it comes to attempting to predict the outcomes of elections. There are so many different media outlets, researchers, think tanks, and political hobbyists who attempt to predict the outcomes of elections. I'll be using the predictions from three different sources: the [Cook Political Report](https://www.cookpolitical.com/ratings/house-race-ratings/187562), [Inside Elections](http://www.insideelections.com/ratings/house/2018-house-ratings-september-28-2018), and [Larry Sabato's Crystal Ball](https://insideelections.com/archive/year/2018). While these sources ascribe descriptive values to the outcome of races (solid, lean, etc) all three of them are widely-known and widely respected. What surprised me is that some outlets like FiveThirtyEight incorporate these predictions into their models. Perhaps what these experts are able to capture are things like candidate quality which can be hard to determine based on other data that is out there.

When experts predict the outcome of a race, they give it a descriptor that can roughly correspond to different voteshares. I've chosen to give the following Democrat voteshares to the following predictions:

Solid Democrat - 60%
Likely Democrat - 55%
Lean Democrat - 52.5%
Tilt Democrat - 51.5%
Toss-up - 50%
Tilt Republican - 48.5%
Lean Republican - 47.5%
Likely Republican - 45%
Solid Republican - 40%

Let's look at some maps. The following map shows the two party vote share by district in the 2018 house midterm election:

```{r map1, echo = FALSE, warning = FALSE}
vote_share_actual
```

Plotted below is the average of the expert predictions for each district using the voteshare values I ascribed. 

```{r map2, echo = FALSE, warning = FALSE}
vote_share_predicted
```

And below is a map that shows the difference between expert predictions and actual voteshare outcomes. Note that positive (blue) values indicate that Democrats fared better than experts predicted, and negative (red) values indicate that Democrats fared worse than experts predicted.

```{r map3, echo = FALSE, warning = FALSE}
vote_share_difference
```

As we can see, it looks like Democrats did a little bit better than experts predicted in many of the districts in the 2018 midterm election, with only a few races where Democrats fared worse than expected. There were a few districts which were labeled as strong Democrat/Republican that had a difference of 40 points. While at first it may seem like a gross inaccuracy, these districts are ones where a candidate ran uncontested. Based on how I coded the "strong" values, uncontested races will always put out a margin difference of 40 points. This highlights the arbitrariness of my ascribed values but doesn't take away from the overall trends of these expert predictions, namely that Democrats exceeded expectations.

# Adding Incumbency and Expert Predictions to My Model

For last week's blog post, I wasn't able to add polling data to my model. I've revisited it here. I've chosen to look at national generic polls for two reasons. First, especially if we're going back a few decades, district level and other kinds of polls become much harder to find. I would like to have a lot of observations in order to improve my model. Second, most people don't know who their House representative is, so generic polls are often the best way to tell who they will vote for their House election, if they decide to turn out. As we've discussed previously, polls get more accurate the closer you are to the start of the election since people start making up their minds as the election approaches. What I've done is average the partisan support of all polls taken 45 days or fewer before the election for each election cycle. 

For my model, I'm first going to predict the seat share of the incumbent president's party in the House by looking at whether the incumbent majority party in the House is the same as the president's party, whether an election is a midterm, and GDP growth in the last quarter before the election as an economic indicator. As I've discussed in previous weeks, observers of politics have noted that the president's party tends to lose seats during the midterm election, especially when the economy is doing poorly in the eyes of voters. I include the incumbent party in the house because I want to see whether voters are sensitive to the majority party of the House itself when voting. I've opted not to include expert predictions because I think using expert predictions would be cheating in some way and somewhat difficult to implement given my national approach. It could also expose my model to significant bias if experts are all biased in the same direction, so I'll stick to my own predictions for now. 

Below is a stargazer table which looks at the coefficients of my models:

```{r, include = FALSE}
library(tidyverse)
library(stargazer)
library(tinytex)
library(lubridate)
library(pandoc)

# Load model data
seats_data <- read_csv("../data/house_popvote_seats.csv")
gdp_quarterly <- read_csv("../data/GDP_quarterly.csv")
polls_data <- read_csv("../data/polls_df.csv")

# Wrangle data
ec_data <- gdp_quarterly %>% 
  filter(quarter_cycle == 8) %>% 
  select(year, GDP_growth_pct)

polls_wrangled <- polls_data %>% 
  filter(days_until_election <= 45) %>% 
  mutate(D_support = ifelse(party == "D", support, 100 - support)) %>% 
  group_by(year) %>% 
  summarise(D_avg_poll_support = mean(D_support) / 100) %>% 
  mutate(R_avg_poll_support = 1 - D_avg_poll_support)

model_seats_data <- seats_data %>% 
  select(year, R_seats, D_seats, R_majorvote_pct, D_majorvote_pct, president_party, H_incumbent_party) %>% 
  mutate(president_party_dummy = ifelse(president_party == "D", 1, 0)) %>% # president's party dummy
  mutate(H_incumbent_party_dummy = ifelse(H_incumbent_party == president_party, 1, 0)) %>% # incumbent party in House dummy
  mutate(midterm_dummy = ifelse(year %% 4, 1, 0)) %>% # midterm election dummy
  inner_join(ec_data, by = "year") %>% 
  left_join(polls_wrangled, by = "year") %>% 
  mutate(incumbent_pres_majorvote = ifelse(president_party == "D", D_majorvote_pct, R_majorvote_pct),
         incumbent_pres_seats = ifelse(president_party == "D", D_seats, R_seats),
         incumbent_pres_seatshare = incumbent_pres_seats / 435,
         incumbent_pres_poll_support = ifelse(president_party == "D", D_avg_poll_support, R_avg_poll_support))

# Model 1: Fundamentals without House majority party
no_house_model <- lm(incumbent_pres_seatshare ~ midterm_dummy + GDP_growth_pct, data = model_seats_data)
# stargazer(no_house_model, type = "text")

# Model 2: Fundamentals with House majority party
house_model <- lm(incumbent_pres_seatshare ~ H_incumbent_party_dummy + midterm_dummy + GDP_growth_pct, data = model_seats_data)
# stargazer(house_model, type = "text")

# Model 3: Polls only
polls_only_model <- lm(incumbent_pres_seatshare ~ incumbent_pres_poll_support, data = model_seats_data)
# stargazer(polls_only_model, type = "text")

# Model 4: Everything combined
combo <- lm(incumbent_pres_seatshare ~ H_incumbent_party_dummy + midterm_dummy + incumbent_pres_poll_support + GDP_growth_pct, data = model_seats_data)
stargazer(combo, type = "text")

# stargazer(no_house_model, house_model, polls_only_model, combo, title = "Model Coefficients",
#           align = TRUE, type = "html", font.size = "small", header = FALSE, dep.var.labels = "Seatshare of Incumbent President's Party",
#           covariate.labels = c("House Majority Party Same as President", "Midterm Election", "GDP Growth Pct",
#                                "Incumbent President's Party Poll Support"))



# Load and clean prediction data
polls_2022 <- read_csv("../data/generic_ballot_averages.csv") %>% # pulled from https://projects.fivethirtyeight.com/polls/generic-ballot/ on 10/17 
  filter(cycle == 2022) %>% 
  mutate(date = ymd(date)) %>% 
  filter(date >= ymd("2022-09-24")) %>% 
  mutate(D_support = ifelse(candidate == "Democrats", pct_estimate, 100 - pct_estimate)) %>% 
  summarise(D_avg_poll_support = mean(D_support) / 100) %>% 
  mutate(R_avg_poll_support = 1 - D_avg_poll_support)
  
prediction_data_2022 <- NA
prediction_data_2022$midterm_dummy <- 1
prediction_data_2022$incumbent_pres_poll_support <- polls_2022$D_avg_poll_support
prediction_data_2022$H_incumbent_party_dummy <- 1
prediction_data_2022$GDP_growth_pct <- -0.9 # Note this is Q2 GDP growth as Q3 hasn't come out yet, source is Bureau of Economic Analysis https://www.bea.gov/news/2022/gross-domestic-product-second-quarter-2022-advance-estimate

# Make a prediction
predictions <- data.frame(model = "prediction",
                          incumb_model = predict(house_model, prediction_data_2022),
                          combined_model = predict(combo, prediction_data_2022))
```
```{r stars, echo = FALSE}
stargazer(no_house_model, house_model, polls_only_model, combo, title = "Model Coefficients",
          align = TRUE, type = "text", font.size = "small", header = FALSE, dep.var.labels = "Seatshare of Incumbent President's Party",
          covariate.labels = c("House Majority Party Same as President", "Midterm Election", "GDP Growth Pct",
                               "Incumbent President's Party Poll Support"),
          omit.stat = c("LL","ser","f"))
```
These significance codes are really promising, although they do make sense. Like in week 2, it looks like GDP doesn't have much to do with how people vote in House elections. This model predicts that when the incumbent House majority party has the same party as the president, that party will get increased seatshare. This could be the model picking up on periods of time when one party was incredibly successful in getting elected and predicting this would have a lingering effect, which at least makes sense intuitively. Likewise, it also predicts that the president's party does worse during midterm elections with a high significance code. Similarly, doing well in the polls seems to predict electoral wins with a high significance code. 

Now let's look at my predictions using the 2nd and 4th models:

```{r table, asis = TRUE}
predictions
```

It looks like both my incumbency only model and my combined incumbency and polling model predict the Democrats to win the House election with an overall 52.3% seatshare. Hopefully my next post will include some interesting new changes to tighten this up a bit as I personally am not too sure the Democrats will maintain their current House majority through the midterms.